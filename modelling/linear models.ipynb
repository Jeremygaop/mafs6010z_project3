{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cd09ae7-14bd-4519-9946-78d220666553",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tools import FeatureEngineer\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, ElasticNet\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8398f90-64c5-421f-9758-de2acaeeb57a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "bnb = pd.read_csv('bnb.csv')\n",
    "bnb.drop(columns='Asset_ID', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6db1db8-8597-4eb0-87ec-13146ebea50b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "    timestamp  Count     Open     High      Low    Close   Volume       VWAP  \\\n0  1523956260    7.0  12.4195  12.4195  12.4101  12.4195   794.70  12.411386   \n1  1523956320   33.0  12.4195  12.4195  12.4001  12.4150  1117.73  12.407532   \n2  1523956380   32.0  12.4150  12.4195  12.4003  12.4100  1062.37  12.401607   \n3  1523956440   38.0  12.4006  12.4100  12.3931  12.4000  2259.55  12.399251   \n4  1523956500   79.0  12.4000  12.4210  12.3930  12.3942  7113.37  12.406144   \n\n     Target  open_sub_close  ...    PSAR-  STC  TRIX  VI  VI+  VI-  WMA  \\\n0 -0.004366          0.0000  ...      NaN  NaN   NaN NaN  NaN  NaN  NaN   \n1 -0.003940          0.0045  ...      NaN  NaN   NaN NaN  NaN  NaN  NaN   \n2 -0.003153          0.0050  ...  12.4195  NaN   NaN NaN  NaN  NaN  NaN   \n3 -0.003429          0.0006  ...  12.4195  NaN   NaN NaN  NaN  NaN  NaN   \n4 -0.002187          0.0058  ...      NaN  NaN   NaN NaN  NaN  NaN  NaN   \n\n         CR       DLR        DR  \n0  0.000000       NaN       NaN  \n1 -0.036233 -0.036240 -0.036233  \n2 -0.076493 -0.040282 -0.040274  \n3 -0.157011 -0.080613 -0.080580  \n4 -0.203712 -0.046785 -0.046774  \n\n[5 rows x 78 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>timestamp</th>\n      <th>Count</th>\n      <th>Open</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Close</th>\n      <th>Volume</th>\n      <th>VWAP</th>\n      <th>Target</th>\n      <th>open_sub_close</th>\n      <th>...</th>\n      <th>PSAR-</th>\n      <th>STC</th>\n      <th>TRIX</th>\n      <th>VI</th>\n      <th>VI+</th>\n      <th>VI-</th>\n      <th>WMA</th>\n      <th>CR</th>\n      <th>DLR</th>\n      <th>DR</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1523956260</td>\n      <td>7.0</td>\n      <td>12.4195</td>\n      <td>12.4195</td>\n      <td>12.4101</td>\n      <td>12.4195</td>\n      <td>794.70</td>\n      <td>12.411386</td>\n      <td>-0.004366</td>\n      <td>0.0000</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1523956320</td>\n      <td>33.0</td>\n      <td>12.4195</td>\n      <td>12.4195</td>\n      <td>12.4001</td>\n      <td>12.4150</td>\n      <td>1117.73</td>\n      <td>12.407532</td>\n      <td>-0.003940</td>\n      <td>0.0045</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-0.036233</td>\n      <td>-0.036240</td>\n      <td>-0.036233</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1523956380</td>\n      <td>32.0</td>\n      <td>12.4150</td>\n      <td>12.4195</td>\n      <td>12.4003</td>\n      <td>12.4100</td>\n      <td>1062.37</td>\n      <td>12.401607</td>\n      <td>-0.003153</td>\n      <td>0.0050</td>\n      <td>...</td>\n      <td>12.4195</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-0.076493</td>\n      <td>-0.040282</td>\n      <td>-0.040274</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1523956440</td>\n      <td>38.0</td>\n      <td>12.4006</td>\n      <td>12.4100</td>\n      <td>12.3931</td>\n      <td>12.4000</td>\n      <td>2259.55</td>\n      <td>12.399251</td>\n      <td>-0.003429</td>\n      <td>0.0006</td>\n      <td>...</td>\n      <td>12.4195</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-0.157011</td>\n      <td>-0.080613</td>\n      <td>-0.080580</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1523956500</td>\n      <td>79.0</td>\n      <td>12.4000</td>\n      <td>12.4210</td>\n      <td>12.3930</td>\n      <td>12.3942</td>\n      <td>7113.37</td>\n      <td>12.406144</td>\n      <td>-0.002187</td>\n      <td>0.0058</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-0.203712</td>\n      <td>-0.046785</td>\n      <td>-0.046774</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 78 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fe = FeatureEngineer()\n",
    "bnb = fe.build_technical_indicators(bnb)\n",
    "bnb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9914ebad-a454-41c0-91e7-9326bdc268f0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RSI_stoch', 'RSI_stoch_d', 'RSI_stoch_k', 'MFI', 'PSAR+', 'PSAR-']\n",
      "[1905, 2193, 2049, 3153, 888055, 915717]\n"
     ]
    }
   ],
   "source": [
    "# inspect missing values\n",
    "temp = bnb.isna().sum()\n",
    "print([i for i in temp.index if temp[i] > 1000])\n",
    "print([temp[i] for i in temp.index if temp[i] > 1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6104538a-5dc3-49f6-b7ce-96c77ef65448",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# drop columns with too many NAs\n",
    "bnb.drop(columns=['KAMA', 'PSAR+', 'PSAR-'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0824a566-9abe-48ac-a83b-259d8c70d53a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "timestamp    0\nCount        0\nOpen         0\nHigh         0\nLow          0\n            ..\nVI-          0\nWMA          0\nCR           0\nDLR          0\nDR           0\nLength: 75, dtype: int64"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop NAs\n",
    "bnb.dropna(axis=0, inplace=True)\n",
    "bnb.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b83e8ca6-1195-4fff-9fd1-26a0f079e5d7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([ 697988,  697989,  697990,  697991,  697992,  697993,  697994,\n",
      "             697995,  697996,  787255,  787256,  787257,  787259,  787260,\n",
      "             787261,  787262,  787263,  787264,  787289,  787291,  787292,\n",
      "             787293,  787294,  787317,  787318,  787319,  787320,  787321,\n",
      "             787322,  787323,  787324,  787325,  787326,  787327,  787532,\n",
      "             787533,  787534,  787570,  787664,  787665,  787955,  787957,\n",
      "             787958,  787959,  788065,  788066,  788080,  788082,  798090,\n",
      "             798091,  798092,  954316,  954319,  954321,  954323,  954324,\n",
      "             954325,  969425,  969426,  969427, 1063757, 1063758, 1063759,\n",
      "            1063760, 1063764, 1063765, 1063768, 1063769, 1063771, 1063772,\n",
      "            1063798, 1063799, 1063800, 1063809, 1063810, 1063811, 1063872,\n",
      "            1063873, 1155936, 1155937, 1155972, 1155974, 1155976, 1155978,\n",
      "            1156057, 1156073, 1156076, 1156077, 1156080, 1156081, 1156083],\n",
      "           dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "# check if df contains infinite values\n",
    "r = bnb.index[np.isinf(bnb).any(1)]\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79faf3c6-42f2-4517-8ae0-ca1d686c075f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "bnb.drop([i for i in r], axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "916012d3-b33d-4e25-a175-5a3b71bef05e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "           timestamp     Count      Open      High       Low     Close  \\\ntimestamp   1.000000  0.455384  0.653054  0.653041  0.653075  0.653053   \nCount       0.455384  1.000000  0.600764  0.601603  0.599749  0.600683   \nOpen        0.653054  0.600764  1.000000  0.999998  0.999998  0.999998   \nHigh        0.653041  0.601603  0.999998  1.000000  0.999994  0.999998   \nLow         0.653075  0.599749  0.999998  0.999994  1.000000  0.999998   \n...              ...       ...       ...       ...       ...       ...   \nVI-         0.101319  0.061422  0.092363  0.092306  0.092266  0.092247   \nWMA         0.653053  0.600835  0.999998  0.999997  0.999996  0.999996   \nCR          0.653053  0.600683  0.999998  0.999998  0.999998  1.000000   \nDLR         0.000995 -0.026222 -0.000399  0.000235  0.000293  0.000808   \nDR          0.001154 -0.024679 -0.000201  0.000437  0.000487  0.001006   \n\n             Volume      VWAP    Target  open_sub_close  ...      PSAR  \\\ntimestamp  0.114014  0.653057  0.002765        0.002816  ...  0.653062   \nCount      0.507294  0.600682  0.012887        0.039572  ...  0.600851   \nOpen       0.065864  0.999999 -0.001489        0.004342  ...  0.999971   \nHigh       0.066385  0.999998 -0.001497        0.003221  ...  0.999968   \nLow        0.065236  0.999999 -0.001498        0.003082  ...  0.999967   \n...             ...       ...       ...             ...  ...       ...   \nVI-       -0.000867  0.092274  0.003984        0.053769  ...  0.093879   \nWMA        0.065899  0.999997 -0.001484        0.003966  ...  0.999980   \nCR         0.065818  0.999999 -0.001500        0.002175  ...  0.999967   \nDLR       -0.037896  0.000308 -0.005916       -0.557282  ... -0.000943   \nDR        -0.036033  0.000506 -0.005890       -0.557111  ... -0.000743   \n\n                STC      TRIX        VI       VI+       VI-       WMA  \\\ntimestamp  0.001778  0.006659  0.003630  0.108174  0.101319  0.653053   \nCount     -0.002977 -0.024643 -0.002600  0.056555  0.061422  0.600835   \nOpen       0.000077  0.005279  0.006751  0.105078  0.092363  0.999998   \nHigh       0.000096  0.005148  0.006787  0.105091  0.092306  0.999997   \nLow        0.000141  0.005411  0.006889  0.105241  0.092266  0.999996   \n...             ...       ...       ...       ...       ...       ...   \nVI-       -0.647129 -0.384579 -0.939508 -0.765278  1.000000  0.092754   \nWMA       -0.000288  0.005121  0.006325  0.104670  0.092754  1.000000   \nCR         0.000155  0.005281  0.006881  0.105207  0.092247  0.999996   \nDLR        0.069754  0.003529  0.136757  0.133220 -0.123745 -0.000246   \nDR         0.069703  0.002931  0.136638  0.133009 -0.123733 -0.000047   \n\n                 CR       DLR        DR  \ntimestamp  0.653053  0.000995  0.001154  \nCount      0.600683 -0.026222 -0.024679  \nOpen       0.999998 -0.000399 -0.000201  \nHigh       0.999998  0.000235  0.000437  \nLow        0.999998  0.000293  0.000487  \n...             ...       ...       ...  \nVI-        0.092247 -0.123745 -0.123733  \nWMA        0.999996 -0.000246 -0.000047  \nCR         1.000000  0.000808  0.001006  \nDLR        0.000808  1.000000  0.999966  \nDR         0.001006  0.999966  1.000000  \n\n[75 rows x 75 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>timestamp</th>\n      <th>Count</th>\n      <th>Open</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Close</th>\n      <th>Volume</th>\n      <th>VWAP</th>\n      <th>Target</th>\n      <th>open_sub_close</th>\n      <th>...</th>\n      <th>PSAR</th>\n      <th>STC</th>\n      <th>TRIX</th>\n      <th>VI</th>\n      <th>VI+</th>\n      <th>VI-</th>\n      <th>WMA</th>\n      <th>CR</th>\n      <th>DLR</th>\n      <th>DR</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>timestamp</th>\n      <td>1.000000</td>\n      <td>0.455384</td>\n      <td>0.653054</td>\n      <td>0.653041</td>\n      <td>0.653075</td>\n      <td>0.653053</td>\n      <td>0.114014</td>\n      <td>0.653057</td>\n      <td>0.002765</td>\n      <td>0.002816</td>\n      <td>...</td>\n      <td>0.653062</td>\n      <td>0.001778</td>\n      <td>0.006659</td>\n      <td>0.003630</td>\n      <td>0.108174</td>\n      <td>0.101319</td>\n      <td>0.653053</td>\n      <td>0.653053</td>\n      <td>0.000995</td>\n      <td>0.001154</td>\n    </tr>\n    <tr>\n      <th>Count</th>\n      <td>0.455384</td>\n      <td>1.000000</td>\n      <td>0.600764</td>\n      <td>0.601603</td>\n      <td>0.599749</td>\n      <td>0.600683</td>\n      <td>0.507294</td>\n      <td>0.600682</td>\n      <td>0.012887</td>\n      <td>0.039572</td>\n      <td>...</td>\n      <td>0.600851</td>\n      <td>-0.002977</td>\n      <td>-0.024643</td>\n      <td>-0.002600</td>\n      <td>0.056555</td>\n      <td>0.061422</td>\n      <td>0.600835</td>\n      <td>0.600683</td>\n      <td>-0.026222</td>\n      <td>-0.024679</td>\n    </tr>\n    <tr>\n      <th>Open</th>\n      <td>0.653054</td>\n      <td>0.600764</td>\n      <td>1.000000</td>\n      <td>0.999998</td>\n      <td>0.999998</td>\n      <td>0.999998</td>\n      <td>0.065864</td>\n      <td>0.999999</td>\n      <td>-0.001489</td>\n      <td>0.004342</td>\n      <td>...</td>\n      <td>0.999971</td>\n      <td>0.000077</td>\n      <td>0.005279</td>\n      <td>0.006751</td>\n      <td>0.105078</td>\n      <td>0.092363</td>\n      <td>0.999998</td>\n      <td>0.999998</td>\n      <td>-0.000399</td>\n      <td>-0.000201</td>\n    </tr>\n    <tr>\n      <th>High</th>\n      <td>0.653041</td>\n      <td>0.601603</td>\n      <td>0.999998</td>\n      <td>1.000000</td>\n      <td>0.999994</td>\n      <td>0.999998</td>\n      <td>0.066385</td>\n      <td>0.999998</td>\n      <td>-0.001497</td>\n      <td>0.003221</td>\n      <td>...</td>\n      <td>0.999968</td>\n      <td>0.000096</td>\n      <td>0.005148</td>\n      <td>0.006787</td>\n      <td>0.105091</td>\n      <td>0.092306</td>\n      <td>0.999997</td>\n      <td>0.999998</td>\n      <td>0.000235</td>\n      <td>0.000437</td>\n    </tr>\n    <tr>\n      <th>Low</th>\n      <td>0.653075</td>\n      <td>0.599749</td>\n      <td>0.999998</td>\n      <td>0.999994</td>\n      <td>1.000000</td>\n      <td>0.999998</td>\n      <td>0.065236</td>\n      <td>0.999999</td>\n      <td>-0.001498</td>\n      <td>0.003082</td>\n      <td>...</td>\n      <td>0.999967</td>\n      <td>0.000141</td>\n      <td>0.005411</td>\n      <td>0.006889</td>\n      <td>0.105241</td>\n      <td>0.092266</td>\n      <td>0.999996</td>\n      <td>0.999998</td>\n      <td>0.000293</td>\n      <td>0.000487</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>VI-</th>\n      <td>0.101319</td>\n      <td>0.061422</td>\n      <td>0.092363</td>\n      <td>0.092306</td>\n      <td>0.092266</td>\n      <td>0.092247</td>\n      <td>-0.000867</td>\n      <td>0.092274</td>\n      <td>0.003984</td>\n      <td>0.053769</td>\n      <td>...</td>\n      <td>0.093879</td>\n      <td>-0.647129</td>\n      <td>-0.384579</td>\n      <td>-0.939508</td>\n      <td>-0.765278</td>\n      <td>1.000000</td>\n      <td>0.092754</td>\n      <td>0.092247</td>\n      <td>-0.123745</td>\n      <td>-0.123733</td>\n    </tr>\n    <tr>\n      <th>WMA</th>\n      <td>0.653053</td>\n      <td>0.600835</td>\n      <td>0.999998</td>\n      <td>0.999997</td>\n      <td>0.999996</td>\n      <td>0.999996</td>\n      <td>0.065899</td>\n      <td>0.999997</td>\n      <td>-0.001484</td>\n      <td>0.003966</td>\n      <td>...</td>\n      <td>0.999980</td>\n      <td>-0.000288</td>\n      <td>0.005121</td>\n      <td>0.006325</td>\n      <td>0.104670</td>\n      <td>0.092754</td>\n      <td>1.000000</td>\n      <td>0.999996</td>\n      <td>-0.000246</td>\n      <td>-0.000047</td>\n    </tr>\n    <tr>\n      <th>CR</th>\n      <td>0.653053</td>\n      <td>0.600683</td>\n      <td>0.999998</td>\n      <td>0.999998</td>\n      <td>0.999998</td>\n      <td>1.000000</td>\n      <td>0.065818</td>\n      <td>0.999999</td>\n      <td>-0.001500</td>\n      <td>0.002175</td>\n      <td>...</td>\n      <td>0.999967</td>\n      <td>0.000155</td>\n      <td>0.005281</td>\n      <td>0.006881</td>\n      <td>0.105207</td>\n      <td>0.092247</td>\n      <td>0.999996</td>\n      <td>1.000000</td>\n      <td>0.000808</td>\n      <td>0.001006</td>\n    </tr>\n    <tr>\n      <th>DLR</th>\n      <td>0.000995</td>\n      <td>-0.026222</td>\n      <td>-0.000399</td>\n      <td>0.000235</td>\n      <td>0.000293</td>\n      <td>0.000808</td>\n      <td>-0.037896</td>\n      <td>0.000308</td>\n      <td>-0.005916</td>\n      <td>-0.557282</td>\n      <td>...</td>\n      <td>-0.000943</td>\n      <td>0.069754</td>\n      <td>0.003529</td>\n      <td>0.136757</td>\n      <td>0.133220</td>\n      <td>-0.123745</td>\n      <td>-0.000246</td>\n      <td>0.000808</td>\n      <td>1.000000</td>\n      <td>0.999966</td>\n    </tr>\n    <tr>\n      <th>DR</th>\n      <td>0.001154</td>\n      <td>-0.024679</td>\n      <td>-0.000201</td>\n      <td>0.000437</td>\n      <td>0.000487</td>\n      <td>0.001006</td>\n      <td>-0.036033</td>\n      <td>0.000506</td>\n      <td>-0.005890</td>\n      <td>-0.557111</td>\n      <td>...</td>\n      <td>-0.000743</td>\n      <td>0.069703</td>\n      <td>0.002931</td>\n      <td>0.136638</td>\n      <td>0.133009</td>\n      <td>-0.123733</td>\n      <td>-0.000047</td>\n      <td>0.001006</td>\n      <td>0.999966</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>75 rows × 75 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa04eb17-4926-4453-ad23-dce0a3062933",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def model_training(x, y, split_ratio, scaler, model_list):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=split_ratio, random_state=42)\n",
    "    # x_train = scaler.fit_transform(x_train)\n",
    "    # x_test = scaler.transform(x_test)\n",
    "    for model_name, clf in model_list.items():\n",
    "        clf.fit(x_train, y_train)\n",
    "        y_pred = clf.predict(x_test)\n",
    "        print(model_name)\n",
    "        print('R^2 Score:', r2_score(y_test, y_pred))\n",
    "        print('Mean Absolute Error:', mean_absolute_error(y_test, y_pred))\n",
    "        print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "faae6090-8e6c-47b8-85cc-17d09078d996",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear regression\n",
      "R^2 Score: 0.0008145034851070321\n",
      "Mean Absolute Error: 0.0027143575457516237\n",
      "Root Mean Squared Error: 0.004348497068449981\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dorothy\\anaconda3\\envs\\quiz\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.10755e-42): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ridge\n",
      "R^2 Score: 0.002944262645648066\n",
      "Mean Absolute Error: 0.002711747846550771\n",
      "Root Mean Squared Error: 0.00434386019579549\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dorothy\\anaconda3\\envs\\quiz\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.390e+01, tolerance: 2.780e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elastic net\n",
      "R^2 Score: 0.00025167105120349476\n",
      "Mean Absolute Error: 0.002713695446123922\n",
      "Root Mean Squared Error: 0.00434972163117337\n",
      "\n"
     ]
    }
   ],
   "source": [
    "split_ratio = 0.2\n",
    "scaler = MinMaxScaler()\n",
    "x = bnb.drop(columns=['Target', 'Open', 'High', 'Low', 'VWAP'])\n",
    "y = bnb['Target']\n",
    "model_list = {'linear regression': LinearRegression(),\n",
    "              'ridge': Ridge(),\n",
    "              'elastic net': ElasticNet()}\n",
    "\n",
    "model_training(x, y, split_ratio, scaler, model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c843c0b4-208f-42f0-a02a-63b26366210b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear regression\n",
      "R^2 Score: 0.0008923505211246852\n",
      "Mean Absolute Error: 0.0027135342217234665\n",
      "Root Mean Squared Error: 0.004348327668372185\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dorothy\\anaconda3\\envs\\quiz\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.1096e-42): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ridge\n",
      "R^2 Score: 0.0030557416759781075\n",
      "Mean Absolute Error: 0.002711691299159997\n",
      "Root Mean Squared Error: 0.00434361734936229\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dorothy\\anaconda3\\envs\\quiz\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.390e+01, tolerance: 2.780e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elastic net\n",
      "R^2 Score: 0.00025167105120349476\n",
      "Mean Absolute Error: 0.002713695446123922\n",
      "Root Mean Squared Error: 0.00434972163117337\n",
      "\n"
     ]
    }
   ],
   "source": [
    "split_ratio = 0.2\n",
    "scaler = StandardScaler()\n",
    "x = bnb.drop(columns=['Target'])\n",
    "y = bnb['Target']\n",
    "model_list = {'linear regression': LinearRegression(),\n",
    "              'ridge': Ridge(),\n",
    "              'elastic net': ElasticNet()}\n",
    "\n",
    "model_training(x, y, split_ratio, scaler, model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "836f4000-faae-429b-8c54-cb4f1e465f3a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# split data\n",
    "x, y = np.array(bnb.drop(columns='Target')), np.array(bnb['Target'])\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# normalization\n",
    "scaler = MinMaxScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "# convert to tensor\n",
    "x_train, x_test = torch.from_numpy(x_train).float(), torch.from_numpy(x_test).float()\n",
    "y_train, y_test = torch.from_numpy(y_train).float(), torch.from_numpy(y_test).float()\n",
    "y_train = y_train.view(y_train.shape[0], 1)\n",
    "\n",
    "n_samples, n_features = x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8fcd0168-5713-4d55-a3ba-598a9391879a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# construct model\n",
    "input_size, output_size = n_features, 1\n",
    "model = nn.Linear(input_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eebd9d5e-1852-4965-ac40-bed9fa5b7d94",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# loss & optimizer\n",
    "learning_rate = 0.01\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21b56d67-9bdf-4c27-afa6-96984781ba05",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 50, loss = 0.0041\n",
      "epoch: 100, loss = 0.0032\n",
      "epoch: 150, loss = 0.0025\n",
      "epoch: 200, loss = 0.0021\n",
      "epoch: 250, loss = 0.0017\n",
      "epoch: 300, loss = 0.0015\n",
      "epoch: 350, loss = 0.0013\n",
      "epoch: 400, loss = 0.0011\n",
      "epoch: 450, loss = 0.0010\n",
      "epoch: 500, loss = 0.0008\n",
      "epoch: 550, loss = 0.0007\n",
      "epoch: 600, loss = 0.0007\n",
      "epoch: 650, loss = 0.0006\n",
      "epoch: 700, loss = 0.0006\n",
      "epoch: 750, loss = 0.0005\n",
      "epoch: 800, loss = 0.0005\n",
      "epoch: 850, loss = 0.0004\n",
      "epoch: 900, loss = 0.0004\n",
      "epoch: 950, loss = 0.0004\n",
      "epoch: 1000, loss = 0.0004\n",
      "epoch: 1050, loss = 0.0003\n",
      "epoch: 1100, loss = 0.0003\n",
      "epoch: 1150, loss = 0.0003\n",
      "epoch: 1200, loss = 0.0003\n",
      "epoch: 1250, loss = 0.0003\n",
      "epoch: 1300, loss = 0.0003\n",
      "epoch: 1350, loss = 0.0003\n",
      "epoch: 1400, loss = 0.0003\n",
      "epoch: 1450, loss = 0.0002\n",
      "epoch: 1500, loss = 0.0002\n",
      "epoch: 1550, loss = 0.0002\n",
      "epoch: 1600, loss = 0.0002\n",
      "epoch: 1650, loss = 0.0002\n",
      "epoch: 1700, loss = 0.0002\n",
      "epoch: 1750, loss = 0.0002\n",
      "epoch: 1800, loss = 0.0002\n",
      "epoch: 1850, loss = 0.0002\n",
      "epoch: 1900, loss = 0.0002\n",
      "epoch: 1950, loss = 0.0002\n",
      "epoch: 2000, loss = 0.0002\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "num_epochs = 2000\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # forward pass and loss\n",
    "    y_pred = model(x_train)\n",
    "    loss = criterion(y_pred, y_train)\n",
    "    \n",
    "    # backward pass and update\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # zero grad before new step\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if (epoch+1) % 50 == 0:\n",
    "        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54bd1eea-7138-4f32-8e01-1dc61f6bc48d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score: -8.86538682870751\n",
      "Mean Absolute Error: 0.010368501\n",
      "Root Mean Squared Error: 0.013663853\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "pred = model(x_test).detach().numpy()\n",
    "pred = [pred[i] for i in range(len(pred))]\n",
    "print('R^2 Score:', r2_score(y_test, pred))\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da652275-be39-4f91-8477-186e815e136e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}